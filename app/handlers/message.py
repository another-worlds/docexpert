from typing import Dict, Any, List
from datetime import datetime, timedelta
import asyncio
import logging
from langchain_xai import ChatXAI
from langchain.memory import ConversationBufferMemory
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate
from langchain.schema import SystemMessage
from langchain.agents import initialize_agent, Tool, AgentType
from langchain_core.runnables import RunnablePassthrough
import os
from langchain.agents import create_react_agent, AgentExecutor

from ..config import WAIT_TIME, MAX_MESSAGES_PER_BATCH, LLM_MODEL, LLM_TEMPERATURE, XAI_API_KEY
from ..database.mongodb import db
from ..utils.text import normalize_text
from ..utils.language import detect_language
from ..utils.logging import log_async_performance, get_logger, log_user_interaction
from .document import document_handler

# Setup dedicated logger for message pipeline
msg_logger = get_logger('message_pipeline')

class MessageHandler:
    def __init__(self):
        self.llm = ChatXAI(
            api_key=XAI_API_KEY,
            model=LLM_MODEL,
            temperature=LLM_TEMPERATURE
        )
        self.memories = {}
        self.db = db
        self.setup_conversation_chain()
        self.setup_agent_tools()
    
    def setup_conversation_chain(self):
        """Setup the conversation chain with the language model"""
        prompt = ChatPromptTemplate.from_messages([
            SystemMessage(content="""You are a helpful AI assistant capable of communicating in multiple languages and analyzing documents.

            Your tasks:
            1. Understand user messages in any language
            2. Maintain context throughout the conversation
            3. Generate helpful and logical responses
            4. Respond in the same language as the user's message
            5. ALWAYS check and use the available documents for every response
            6. When user asks about documents or their content:
               - Use the provided document context directly
               - DO NOT ask which document they're referring to
               - If the query is document-related, always use the document context
               - Reference specific parts from documents when relevant
               - If you can't find exact information, try to provide related information from documents
            
            When responding in Turkish:
            - Use ASCII characters instead of Turkish special characters
            (Replace: ÄŸ->g, Ã¼->u, ÅŸ->s, Ä±->i, Ã¶->o, Ã§->c)

            Important rules:
            - Keep responses concise and clear
            - Maintain conversation context
            - Match the user's language
            - Be friendly yet professional
            - Adapt your personality to the cultural context of the language being used
            - Never ask which document to use - use all relevant document context provided
            - ALWAYS try to use document context in your responses
            - If you can't find exact information in documents, say what related information you found"""),
            MessagesPlaceholder(variable_name="history"),
            HumanMessagePromptTemplate.from_template("{input}")
        ])

        
        # Create chain using pipe operator
        self.chain = (
            prompt | 
            self.llm | 
            (lambda x: x.content)  # Extract content from response
        )
        
        # Initialize memory
        self.memory = ConversationBufferMemory(
            memory_key="history",
            return_messages=True
        )
    
    def setup_agent_tools(self):
        """Setup tools for the agent"""
        self.tools = [
            Tool(
                name="Document Query",
                func=self.sync_query_documents,
                description="Search for information in user's documents"
            ),
            Tool(
                name="Language Detection",
                func=detect_language,
                description="Detect the language of user messages"
            )
        ]
        
        # Add current_user_id attribute
        self.current_user_id = None
        
        # Create agent with updated prompt template
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", """You are a knowledgeable assistant that provides clear and natural responses while maintaining conversation context.

Key principles:
1. Be direct and concise
2. Use a conversational but professional tone
3. Don't mention using tools or searching documents
4. Respond naturally as if you inherently know the information
5. Keep responses focused and relevant
6. For Turkish, use ASCII characters (ÄŸ->g, Ã¼->u, ÅŸ->s, Ä±->i, Ã¶->o, Ã§->c)
7. Always consider previous conversation context
8. Reference previous exchanges when relevant
9. Maintain a coherent conversation flow
10. If a question refers to previous context, use that context in your response

Available tools:
{tools}

To use a tool, use this format:
Action: the action to take, should be one of [{tool_names}]
Action Input: the input to the action
Observation: the result of the action"""),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad")
        ])
        # Initialize agent with ReAct prompt
        self.agent = initialize_agent(
            tools=self.tools,
            llm=self.llm,
            agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,
            verbose=True,
            handle_parsing_errors=True,
            max_iterations=3,
            memory=ConversationBufferMemory(
                memory_key="chat_history",
                return_messages=True
            )
        )
    
    def get_user_memory(self, user_id: str) -> ConversationBufferMemory:
        """Get or create memory for a user"""
        if user_id not in self.memories:
            self.memories[user_id] = ConversationBufferMemory(
                return_messages=True,
                input_key="input",
                output_key="output"
            )
        return self.memories[user_id]
    
    def get_conversation_history(self, user_id: str) -> str:
        """Get conversation history for a user"""
        # Get recent messages from MongoDB
        recent_messages = list(self.db.message_queue.find(
            {
                "user_id": user_id,
                "is_processed": True,
                "response": {"$exists": True}
            }
        ).sort("timestamp", -1).limit(5))
        
        # Format conversation history
        history = []
        for msg in reversed(recent_messages):
            history.append(f"User: {msg['message']}")
            if msg.get('response'):
                history.append(f"Assistant: {msg['response']}")
        
        return "\n".join(history) if history else ""
    
    def analyze_message_intent(self, message: str) -> str:
        """Analyze the intent of a message"""
        prompt = ChatPromptTemplate.from_template(
            "Analyze the intent and emotion behind this message: {message}"
        )
        chain = prompt | self.llm | (lambda x: x.content)
        return chain.invoke({"message": message})
    
    async def query_documents(self, query: str, user_id: str, k: int = 20) -> Dict[str, Any]:
        """Query user's documents"""
        return await document_handler.query_documents(query, user_id, k)
    
    async def get_document_context(self, query: str, user_id: str) -> Dict[str, Any]:
        """Get relevant context from user's documents"""
        try:
            # Get user's documents from MongoDB
            user_docs = self.db.get_user_documents(user_id)
            if not user_docs:
                return {"context": "", "sources": [], "available_docs": []}

            # Format available documents info
            available_docs = []
            for doc in user_docs:
                metadata = doc.get('metadata', {})
                file_name = metadata.get('file_name', '')
                upload_time = doc.get('upload_time', datetime.utcnow()).strftime('%Y-%m-%d %H:%M')
                status = "âœ…" if doc.get('status') == "processed" else "âŒ"
                available_docs.append(f"- {status} {file_name} (Uploaded: {upload_time})")

            # Query documents with both original query and a summarization query
            doc_response = await self.query_documents(query, user_id, k=5)
            summary_response = await self.query_documents("Summarize the key points from all documents", user_id, k=3)

            # Build context with both specific and general information
            context_parts = []
            
            # Add available documents list
            context_parts.append("Your available documents:")
            context_parts.extend(available_docs)
            context_parts.append("")  # Empty line for separation

            # Add query-specific content if available
            if doc_response and doc_response.get("answer"):
                context_parts.append("Relevant content for your query:")
                context_parts.append(doc_response["answer"])
                context_parts.append("")

            # Add general summary
            if summary_response and summary_response.get("answer"):
                context_parts.append("General context from your documents:")
                context_parts.append(summary_response["answer"])

            # Combine all sources
            all_sources = []
            if doc_response and doc_response.get("sources"):
                all_sources.extend(doc_response["sources"])
            if summary_response and summary_response.get("sources"):
                # Add only unique sources from summary
                existing_ids = {s["metadata"].get("chunk_index") for s in all_sources}
                for source in summary_response["sources"]:
                    if source["metadata"].get("chunk_index") not in existing_ids:
                        all_sources.append(source)

            return {
                "context": "\n".join(context_parts),
                "sources": all_sources,
                "available_docs": available_docs,
                "stats": {
                    "total_docs": doc_response.get("total_docs", 0),
                    "docs_used": doc_response.get("docs_used", 0),
                    "total_chunks_used": len(all_sources)
                }
            }

        except Exception as e:
            print(f"Error getting document context: {str(e)}")
            return {"context": "", "sources": [], "available_docs": [], "stats": {}}
    
    async def process_messages(self, messages: List[Dict[str, Any]], user_id: str) -> str:
        """Process a batch of messages, letting the agent use tools as needed"""
        msg_logger.info(f"ðŸ’¬ Starting message processing for user {user_id}")
        msg_logger.info(f"ðŸ“Š Processing {len(messages)} message(s)")

        # Set current user_id for tools (if needed by sync tools)
        self.current_user_id = user_id

        # Log message details
        for i, msg in enumerate(messages):
            msg_logger.debug(f"ðŸ“ Message {i+1}: '{msg.get('message', '')[:100]}...'")
            msg_logger.debug(f"â° Timestamp: {msg.get('timestamp')}")

        # Get recent conversation history from MongoDB
        msg_logger.debug("ðŸ“š Fetching conversation history")
        recent_history = list(self.db.message_queue.find({
            "user_id": user_id,
            "is_processed": True,
            "response": {"$exists": True}
        }).sort("timestamp", -1).limit(5))

        msg_logger.info(f"ðŸ“œ Found {len(recent_history)} recent conversation entries")

        # Format conversation history for context
        conversation_context = []
        for msg in reversed(recent_history):
            conversation_context.append(f"User: {msg['message']}")
            if msg.get('response'):
                conversation_context.append(f"Assistant: {msg['response']}")

        msg_logger.debug(f"ðŸ”— Built conversation context with {len(conversation_context)} entries")

        # Combine messages
        combined_message = " ".join([msg["message"] for msg in messages])
        msg_logger.info(f"ðŸ“ Combined message length: {len(combined_message)} characters")
        msg_logger.debug(f"ðŸ“„ Combined message preview: '{combined_message[:200]}...'")

        # Detect language
        msg_logger.debug("ðŸŒ Detecting message language")
        detected_lang = detect_language(combined_message)
        msg_logger.info(f"ðŸ—£ï¸  Detected language: {detected_lang}")

        # Normalize if Turkish
        if detected_lang == 'tr':
            msg_logger.debug("ðŸ”„ Applying Turkish text normalization")
            combined_message = normalize_text(combined_message)

        # Get user memory and update with recent history
        msg_logger.debug("ðŸ§  Updating user memory with conversation history")
        memory = self.get_user_memory(user_id)
        for msg in conversation_context:
            if msg.startswith("User: "):
                memory.chat_memory.add_user_message(msg[6:])
            elif msg.startswith("Assistant: "):
                memory.chat_memory.add_ai_message(msg[11:])

        msg_logger.debug(f"ðŸ’­ Memory updated with {len(conversation_context)} context entries")

        try:
            msg_logger.info("ðŸš€ Starting AI response generation (agentic pipeline)")
            # Let the agent decide when to use tools (document/youtube search)
            # Provide only the user query and conversation context
            agent_context = {"user_id": user_id}
            self.agent._current_context = agent_context  # For tool context if needed
            agent_response = await self.agent.agent.arun({
                "input": combined_message,
                "chat_history": memory.chat_memory.messages
            })
            response = agent_response.get("output", "")

            # Optionally, update conversation history with tool usage info if desired
            self.db.message_queue.update_one(
                {"_id": messages[-1]["_id"]},
                {
                    "$set": {
                        "conversation_history": {
                            "user_message": combined_message,
                            "assistant_response": response,
                            "language": detected_lang,
                            "agentic_tools_used": True,
                            "previous_context_used": bool(conversation_context),
                            "timestamp": datetime.utcnow()
                        }
                    }
                }
            )

            return response

        except Exception as e:
            print(f"Error in process_messages: {str(e)}")
            return "Sorry, I couldn't process your request or an error occurred."
    
    async def process_message_queue(self, user_id: str):
        """Process messages in the queue for a user"""
        try:
            # Wait for additional messages
            await asyncio.sleep(WAIT_TIME)
            
            # Get cutoff time
            current_time = datetime.utcnow()
            cutoff_time = current_time - timedelta(minutes=5)
            
            # Get pending messages
            messages = self.db.get_pending_messages(user_id, cutoff_time, MAX_MESSAGES_PER_BATCH)
            
            if not messages:
                return
            
            # Generate batch ID
            batch_id = str(datetime.utcnow())
            message_ids = [msg["_id"] for msg in messages]
            
            # Mark messages as being processed
            self.db.mark_messages_as_processed(message_ids, batch_id)
            
            # Process messages with RAG
            response = await self.process_messages(messages, user_id)
            
            # Update messages with response
            self.db.update_message_response(batch_id, response)
            
            return response
            
        except Exception as e:
            print(f"Error processing messages for user {user_id}: {str(e)}")
            if 'message_ids' in locals():
                self.db.message_queue.update_many(
                    {"_id": {"$in": message_ids}},
                    {
                        "$set": {
                            "processing_error": str(e),
                            "error_timestamp": datetime.utcnow()
                        }
                    }
                )
            raise
    
    def sync_query_documents(self, query: str) -> Dict[str, Any]:
        """Synchronous version of query_documents for the agent tool"""
        try:
            # Create an event loop if one doesn't exist
            try:
                loop = asyncio.get_event_loop()
            except RuntimeError:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
            
            # Run the async function in the event loop
            result = loop.run_until_complete(
                document_handler.query_documents(query, self.current_user_id)
            )
            
            # Format the result for better readability
            if isinstance(result, dict):
                formatted_result = {
                    "answer": result.get("answer", "No relevant information found."),
                    "sources": [
                        f"From {s['metadata'].get('file_name', 'Unknown')}: {s['content'][:200]}..."
                        for s in result.get("sources", [])
                    ]
                }
                return formatted_result
            return {"answer": "No results found", "sources": []}
            
        except Exception as e:
            print(f"Error in sync_query_documents: {str(e)}")
            return {"answer": "Error querying documents", "sources": []}

# Create a singleton instance
message_handler = MessageHandler()
